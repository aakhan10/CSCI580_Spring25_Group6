{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tnF-c6imu3aK"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xK_kAy9HvvTN"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-VrrP36wJYb"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "__TGW2OXwf7x",
    "outputId": "94ce3e27-a023-4370-a576-8e63fbdf1226"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_dataset  = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxXrDd36w7e3",
    "outputId": "a3c108b3-7c82-4c1e-f6cf-9e330b11e3cf"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def ProjectDataLoader():\n",
    "    image_tensors = []\n",
    "    labels = []\n",
    "    png_files = [f for f in os.listdir('/content') if f.lower().endswith('.png')]\n",
    "    for fname in png_files:\n",
    "        if fname.endswith('.png'):\n",
    "            label_str = fname.split('-')[0]\n",
    "            label = int(label_str)\n",
    "            img_path = os.path.join('/content', fname)\n",
    "            img = Image.open(img_path).convert('L')\n",
    "            tensor_img = transform(img)\n",
    "            image_tensors.append(tensor_img)\n",
    "            labels.append(label)\n",
    "    images_tensor = torch.stack(image_tensors)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    return images_tensor, labels_tensor\n",
    "\n",
    "custom_images, custom_labels = ProjectDataLoader()\n",
    "print(f\"Loaded {custom_images.shape[0]} custom images. Label tensor shape: {custom_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-C9AZ7_HUq6"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVofJIbZH7pw"
   },
   "outputs": [],
   "source": [
    "class DigitMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PQVRCctg6ZP"
   },
   "source": [
    "# Training with Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDI30PKGIBs3",
    "outputId": "0e7205c9-5d29-4a56-e1ca-ce0ac0e25473"
   },
   "outputs": [],
   "source": [
    "model = DigitMLP()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoyH_OatIF_H"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEA6NB07Ms9A"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oyyj4ZqrIIx0",
    "outputId": "080768e5-05cc-472b-92b2-5eefa2b47c94"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train_losses = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs} - Training Loss: {avg_loss:.4f} - MNIST Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Hx1DAoIENBnH",
    "outputId": "3dd0300f-cefb-4530-9b78-66a97308d49a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, epochs+1), train_losses, marker='o')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48dqidCvLHs3",
    "outputId": "229e3035-8d3c-44e8-dfc9-66fe7c8d73dd"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "mnist_correct = 0\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    mnist_correct += (predicted == labels).sum().item()\n",
    "mnist_total = len(test_dataset)\n",
    "mnist_accuracy = 100 * mnist_correct / mnist_total\n",
    "print(f\"Final MNIST test accuracy: {mnist_accuracy:.2f}% ({mnist_correct}/{mnist_total} correct)\")\n",
    "\n",
    "custom_images = custom_images.to(device)\n",
    "custom_labels = custom_labels.to(device)\n",
    "with torch.no_grad():\n",
    "    custom_outputs = model(custom_images)\n",
    "    _, custom_preds = torch.max(custom_outputs, 1)\n",
    "    custom_correct = (custom_preds == custom_labels).sum().item()\n",
    "custom_total = custom_labels.size(0)\n",
    "custom_accuracy = 100 * custom_correct / custom_total\n",
    "print(f\"Accuracy on custom digits: {custom_accuracy:.2f}%  ({custom_correct}/{custom_total} correct)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbrajQk3imSs"
   },
   "source": [
    "# Improvement #1 : Expand MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zT7VBRbXiokF"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ExpandedDigitMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExpandedDigitMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57Bl_228qGzI"
   },
   "outputs": [],
   "source": [
    "model = ExpandedDigitMLP()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-I2G2xJarrLK"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oH4qx3xRrrgw",
    "outputId": "cfe9c6ec-c9a1-46f2-d5d7-9045b8e64fc0"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train_losses = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs} - Training Loss: {avg_loss:.4f} - MNIST Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "ilZAjQgxrtRA",
    "outputId": "ffaae8a6-d1b5-4324-98ca-ae9e2465e43a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, epochs+1), train_losses, marker='o')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dK4Za-8vrvSk",
    "outputId": "061cd2a1-4695-48ea-c0ab-c7e683de9220"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "mnist_correct = 0\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    mnist_correct += (predicted == labels).sum().item()\n",
    "mnist_total = len(test_dataset)\n",
    "mnist_accuracy = 100 * mnist_correct / mnist_total\n",
    "print(f\"Final MNIST test accuracy: {mnist_accuracy:.2f}% ({mnist_correct}/{mnist_total} correct)\")\n",
    "\n",
    "custom_images = custom_images.to(device)\n",
    "custom_labels = custom_labels.to(device)\n",
    "with torch.no_grad():\n",
    "    custom_outputs = model(custom_images)\n",
    "    _, custom_preds = torch.max(custom_outputs, 1)\n",
    "    custom_correct = (custom_preds == custom_labels).sum().item()\n",
    "custom_total = custom_labels.size(0)\n",
    "custom_accuracy = 100 * custom_correct / custom_total\n",
    "print(f\"Accuracy on custom digits: {custom_accuracy:.2f}%  ({custom_correct}/{custom_total} correct)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hw35ptOUCx2"
   },
   "source": [
    "# Improvement #2 : Expand MLP Model Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-hBHmhzUCJ9"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ExpandedDigitMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ExpandedDigitMLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_10tpNFwUMjk"
   },
   "outputs": [],
   "source": [
    "model = ExpandedDigitMLP()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypQOOvDAUNKb"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syovHiBnUPLu",
    "outputId": "e4aa0c39-f8f1-440e-ce6f-f74630fddf3e"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train_losses = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs} - Training Loss: {avg_loss:.4f} - MNIST Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Er9AT5aSUTlZ",
    "outputId": "dfbd9793-e935-4eff-e1ec-9446668bd897"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, epochs+1), train_losses, marker='o')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-G4tkAUUVac",
    "outputId": "eebf8967-25fc-4dbe-adae-4d11d2f1c601"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "mnist_correct = 0\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    mnist_correct += (predicted == labels).sum().item()\n",
    "mnist_total = len(test_dataset)\n",
    "mnist_accuracy = 100 * mnist_correct / mnist_total\n",
    "print(f\"Final MNIST test accuracy: {mnist_accuracy:.2f}% ({mnist_correct}/{mnist_total} correct)\")\n",
    "\n",
    "custom_images = custom_images.to(device)\n",
    "custom_labels = custom_labels.to(device)\n",
    "with torch.no_grad():\n",
    "    custom_outputs = model(custom_images)\n",
    "    _, custom_preds = torch.max(custom_outputs, 1)\n",
    "    custom_correct = (custom_preds == custom_labels).sum().item()\n",
    "custom_total = custom_labels.size(0)\n",
    "custom_accuracy = 100 * custom_correct / custom_total\n",
    "print(f\"Accuracy on custom digits: {custom_accuracy:.2f}%  ({custom_correct}/{custom_total} correct)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKVgmXYEUWdt"
   },
   "source": [
    "# Improvement #3 : Training for More Epochs with Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q7Y5Fbtirw6P",
    "outputId": "4abe574f-ca60-4882-bb83-be2d119319a8"
   },
   "outputs": [],
   "source": [
    "model = ExpandedDigitMLP().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "epochs = 15\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = 100 * correct / total\n",
    "    test_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{epochs} - Loss: {avg_loss:.4f} - Test Acc: {accuracy:.2f}% - LR: {scheduler.get_last_lr()[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "tn9R7766QI82",
    "outputId": "8c398e75-2015-42cf-c28c-0a32d4201fd5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, epochs+1), train_losses, marker='o')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4PR6IbmaQOtt",
    "outputId": "9aebf0f3-e2ee-4df5-fdc2-4542143f8435"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "mnist_correct = 0\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    mnist_correct += (predicted == labels).sum().item()\n",
    "mnist_total = len(test_dataset)\n",
    "mnist_accuracy = 100 * mnist_correct / mnist_total\n",
    "print(f\"Final MNIST test accuracy: {mnist_accuracy:.2f}% ({mnist_correct}/{mnist_total} correct)\")\n",
    "\n",
    "custom_images = custom_images.to(device)\n",
    "custom_labels = custom_labels.to(device)\n",
    "with torch.no_grad():\n",
    "    custom_outputs = model(custom_images)\n",
    "    _, custom_preds = torch.max(custom_outputs, 1)\n",
    "    custom_correct = (custom_preds == custom_labels).sum().item()\n",
    "custom_total = custom_labels.size(0)\n",
    "custom_accuracy = 100 * custom_correct / custom_total\n",
    "print(f\"Accuracy on custom digits: {custom_accuracy:.2f}%  ({custom_correct}/{custom_total} correct)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all models and combine their training-loss curves\n",
    "\n",
    "# 1) Prepare a dict to hold each model’s loss curve\n",
    "train_losses = {}\n",
    "\n",
    "# 2) Define your models in a dict for easy iteration\n",
    "models = {\n",
    "    \"Model 1\": model1,\n",
    "    \"Model 2\": model2,\n",
    "    \"Model 3\": model3,\n",
    "    \"Model 4\": model4,\n",
    "}\n",
    "\n",
    "# 3) Train each model, record its loss history\n",
    "for name, mdl in models.items():\n",
    "    print(f\"Training {name}…\")\n",
    "    hist = mdl.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "    )\n",
    "    train_losses[name] = hist.history['loss']\n",
    "\n",
    "# 4) Plot all training-loss curves together\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for name, losses in train_losses.items():\n",
    "    plt.plot(losses, label=name)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss Comparison Across 4 Models')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
